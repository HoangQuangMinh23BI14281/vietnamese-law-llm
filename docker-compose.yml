version: '3.8'

services:
  # 1. Weaviate 
  weaviate:
    image: semitechnologies/weaviate:1.24.1
    command:
      - --host
      - 0.0.0.0
      - --port
      - '8080'
      - --scheme
      - http
    ports:
      - "8080:8080"
      - "50051:50051"
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      DEFAULT_VECTORIZER_MODULE: 'none'
      ENABLE_MODULES: ''
      CLUSTER_HOSTNAME: 'node1'
    volumes:
      - weaviate_data:/var/lib/weaviate

  # 2. Embedding API 
  embedding-api:
    build:
      context: ./services/embedding-api
    ports:
      - "5000:5000"
    environment:
      HF_HOME: "/app/models"
      MODEL_NAME: ${EMBEDDING_MODEL_NAME:-huyydangg/DEk21_hcmute_embedding}
    volumes:
      - ./services/embedding-api/src:/app/src
      - ./models_cache_embedding:/app/models
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]

  # 3. Indexing Service 
  indexing-service:
    build:
      context: ./services/indexing-service
    ports:
      - "5001:5001"
    environment:
      EMBEDDING_API_URL: "http://embedding-api:5000/embed"
      WEAVIATE_URL: "http://weaviate:8080"
    volumes:
      - ./services/indexing-service/src:/app/src
      - ./models_cache_hf:/root/.cache/huggingface
    depends_on:
      - weaviate
      - embedding-api

  # 4. LLM Gateway
  llm-gateway:
    build:
      context: ./services/llm-gateway
    ports:
      - "8001:8001"
    environment:
      WEAVIATE_URL: "http://weaviate:8080"
      EMBEDDING_API_URL: "http://embedding-api:5000/embed"
      HF_HOME: "/app/model_cache"
      MODEL_NAME: ${LLM_MODEL_NAME:-Qwen/Qwen3-0.6B}
    volumes:
      - ./services/llm-gateway/src:/app/src
      - ./models_cache_llm:/app/model_cache
    depends_on:
      - weaviate
      - embedding-api
    # Kích hoạt GPU cho LLM Gateway
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]

  # 5. Frontend 
  frontend:
    build:
      context: ./services/frontend
    ports:
      - "8501:8501"
    environment:
      LLM_GATEWAY_URL: "http://llm-gateway:8001"
      INDEXING_SERVICE_URL: "http://indexing-service:5001"
    volumes:
      - ./services/frontend/src:/app/src
    depends_on:
      - llm-gateway
      - indexing-service

volumes:
  weaviate_data:
