from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from groq import Groq
import os
import requests
import weaviate
import logging

# --- CONFIG ---
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("LLM-Gateway")

app = FastAPI(title="Vietnamese Law LLM Gateway")

# Env Vars
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
WEAVIATE_URL = os.getenv("WEAVIATE_URL", "http://weaviate:8080")
EMBEDDING_API_URL = os.getenv("EMBEDDING_API_URL", "http://embedding-api:5000/embed")

# Init Clients
weaviate_client = weaviate.Client(WEAVIATE_URL)
groq_client = Groq(api_key=GROQ_API_KEY)

class ChatRequest(BaseModel):
    query: str

# H√†m g·ªçi Embedding API
def get_embedding(text):
    try:
        res = requests.post(EMBEDDING_API_URL, json={"text": text}, timeout=10)
        return res.json()["embedding"] if res.status_code == 200 else None
    except Exception as e:
        logger.error(f"Embedding Error: {e}")
        return None

# H√†m t√¨m ki·∫øm trong Weaviate
def search_vector(query_text, limit=4):
    vector = get_embedding(query_text)
    if not vector: return []
    
    try:
        response = (
            weaviate_client.query
            .get("LegalDocument", ["title", "content"])
            .with_near_vector({"vector": vector})
            .with_limit(limit)
            .do()
        )
        return response.get('data', {}).get('Get', {}).get('LegalDocument', [])
    except Exception as e:
        logger.error(f"Vector Search Error: {e}")
        return []

# --- MAIN CHAT ENDPOINT ---
@app.post("/chat")
async def chat_endpoint(req: ChatRequest):
    logger.info(f"üì© Nh·∫≠n c√¢u h·ªèi: {req.query}")
    
    # 1. T√¨m ki·∫øm th√¥ng tin li√™n quan (RAG)
    docs = search_vector(req.query)
    
    # 2. X√¢y d·ª±ng context
    context_str = ""
    sources = []
    if docs:
        context_str += "\n--- TH√îNG TIN PH√ÅP LU·∫¨T THAM KH·∫¢O ---\n"
        for i, d in enumerate(docs, 1):
            context_str += f"[{i}] {d.get('title')}: {d.get('content')}\n"
            sources.append(d.get('title'))
    else:
        context_str = "Kh√¥ng t√¨m th·∫•y vƒÉn b·∫£n lu·∫≠t c·ª• th·ªÉ trong c∆° s·ªü d·ªØ li·ªáu."

    # 3. T·∫°o Prompt cho LLM
    system_prompt = """B·∫°n l√† tr·ª£ l√Ω ph√°p lu·∫≠t Vi·ªát Nam. 
    Nhi·ªám v·ª• c·ªßa b·∫°n l√† tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n th√¥ng tin tham kh·∫£o ƒë∆∞·ª£c cung c·∫•p.
    N·∫øu th√¥ng tin kh√¥ng ƒë·ªß, h√£y n√≥i r√µ l√† b·∫°n kh√¥ng bi·∫øt ch·∫Øc ch·∫Øn, ƒë·ª´ng b·ªãa ƒë·∫∑t ƒëi·ªÅu lu·∫≠t."""
    
    user_prompt = f"C√¢u h·ªèi: {req.query}\n\n{context_str}"

    # 4. G·ªçi Groq LLM
    try:
        completion = groq_client.chat.completions.create(
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            model="llama-3.3-70b-versatile",
            temperature=0.3
        )
        answer = completion.choices[0].message.content
        return {"answer": answer, "sources": list(set(sources))}
        
    except Exception as e:
        logger.error(f"Groq Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))