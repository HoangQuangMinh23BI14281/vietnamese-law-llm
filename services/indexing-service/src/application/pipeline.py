import logging
import os
from src.domain.models import ProcessingResult, LegalChunk # Import type

logger = logging.getLogger(__name__)

class IndexingPipeline:
    def __init__(self, loader, chunker, embedder, db):
        self.loader = loader
        self.chunker = chunker
        self.embedder = embedder
        self.db = db

    def run_pipeline(self, file_path: str):
        filename = os.path.basename(file_path)
        logger.info(f"üöÄ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω file: {filename}")

        try:
            # 1. Load
            raw_text = self.loader.load(file_path)
            if not raw_text:
                raise Exception("File r·ªóng ho·∫∑c kh√¥ng ƒë·ªçc ƒë∆∞·ª£c text")

            # 2. Chunk
            chunks = self.chunker.chunk(raw_text, filename)
            logger.info(f"‚úÇÔ∏è ƒê√£ c·∫Øt th√†nh {len(chunks)} chunks.")

            # 3. Embed & Validate Metadata
            vectors = []
            valid_chunks = []
            
            for chunk in chunks:
                text_content = chunk.text if hasattr(chunk, 'text') else chunk.get('text', '')
                
                # [UPDATE] Ki·ªÉm tra nhanh xem Metadata c√≥ ƒë√∫ng form kh√¥ng (Debug)
                meta = chunk.metadata if hasattr(chunk, 'metadata') else chunk.get('metadata', {})
                if 'article' in meta and meta['article']:
                     # Log sample 1 l·∫ßn th√¥i ƒë·ªÉ debug
                     if len(valid_chunks) == 0: 
                        logger.info(f"üßê Sample Metadata: {meta}")

                try:
                    vec = self.embedder.get_embedding(text_content)
                    
                    if vec and len(vec) > 0:
                        vectors.append(vec)
                        valid_chunks.append(chunk)
                except Exception as e_embed:
                    logger.warning(f"‚ö†Ô∏è L·ªói embedding chunk text '{text_content[:30]}...': {e_embed}")
                    continue # B·ªè qua chunk l·ªói, ch·∫°y ti·∫øp chunk sau

            # 4. Save Batch
            if valid_chunks:
                # H√†m save_chunks c·ªßa DB adapter c·∫ßn x·ª≠ l√Ω vi·ªác map metadata t·ª´ chunk v√†o Weaviate properties
                self.db.save_chunks(valid_chunks, vectors)
                logger.info(f"üíæ ƒê√£ l∆∞u th√†nh c√¥ng {len(valid_chunks)} chunks c√≥ metadata v√†o Weaviate.")
            else:
                logger.warning("‚ö†Ô∏è Kh√¥ng c√≥ chunk n√†o h·ª£p l·ªá ƒë·ªÉ l∆∞u.")

            return ProcessingResult(
                filename=filename,
                status="success",
                total_chunks=len(valid_chunks),
                message="Indexing completed successfully"
            )

        except Exception as e:
            logger.error(f"‚ùå L·ªói Pipeline Fatal: {str(e)}", exc_info=True)
            return ProcessingResult(
                filename=filename,
                status="error",
                message=str(e),
                total_chunks=0
            )